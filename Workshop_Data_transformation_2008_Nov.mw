== Data Transformation Workshop 2. Nov 2008 ==

Present:

Ryan Brinkman - Terry Fox Laboratory, Vancouver

Melanie Courtot - Terry Fox Laboratory, Vancouver,

Philippe Rocca-Serra - EBI

Monnie McGee - Southern Methodist University, Dallas

Tina Boussard, Dept Surgery, Stanford

Helen Parkinson, EBI

Ricardo Pietrobon, Duke University


*******************************************************************************


Action Items:

AI:Hammer BFO/IO for answers on where variables will be in the ontology. Add this to the agenda for Vancouver.

AI:Follow up on input/output lists for dt applications - for Xelig - with Rupali and RP

AI:'center calculation' and 'averaging data transformation' defined classes need attention. MM thinks that these could be conflated. Moving average needs to be under both. Data imputation possibly incorrect - could be a class in itself. Need a new defined class for that - probably objective. 

AI:Need to add the fuzzy clustering methods e.g. 
http://home.dei.polimi.it/matteucc/Clustering/tutorial_html/cmeans.html

AI:Find information for B transformation (existing term) - need an objective. - RB

AI:Background correction - changes to an objective. RB



*************************************************************************************
 


== Day 1. 03 November 2008 ==



1. Introductions for all

2. PPT by James. * add slides

Review of the latest ontology version in OBI.

Use cases - we haven't been able to meet all of a complex use case and so we have broken this down into smaller cases. Want to use one of Ted's and one of Ricardo's use cases to look at the bigger picture and broke down the use cases.

RP:The way that we do things in my group is very standardized, may be a good surprise for OBI

RP:Looks like cells etc are really well represented, what about patients?

JM:We use roles for that, and population for community

PRS:population is what you mean by community? We have ways to describe the recruit process etc

RP:Idea of people and their biomaterials is interesting

PRS:Is a consequence of BFO and the way it models these

Use cases:

Data annotation
Smart forms - autocompletion
QC - nonsense detection - annotation detected etc
Data exchange

JM:Do these fit with your needs RP?

RP:Research divided into basic, T1 clinical, T2 community. We deal a lot with clinical - about propsective studies, how do you formulate a research question. Literature, question, data analysis, from there, into the final manuscript. Very modular. We do data annotation towards the research question, and exclusion/inclusion criteria. QC not applies that much. Data exchange - huge thing in clinical research. What do you mean by that?

JM: Vocabularies, formats etc - all of these. Query across all knowledge bases

RP:CDISC example - protocols for data exchange and the vocabulary are distinct for them

JM:That undersells OBI a bit

RP:variable structure - ordinal, and role - what is the role - outcome, potential confounder - that's exchange. Vocab is about how we state gender.  That's what I mean

JM:If you look at data annotation - that's vocab. Not using more than that. But we can use it as part of a knowledge base and then we have a way to do more than simply use the vocabulary

RP:We have qm within the variable descriptions. Exchange is more interesting than the vocab. We are translating SNOMED into portugese. Not a nice process.

JM:Design decisions - we decided to use some devices to progress. We wanted to use roles to say that a transformation plays a role to avoid multiple parentage. Processes can't be the bearer of roles, this caused a problem for the design. Therefore we had an 'objective' - e.g. clustering, classifying.

MC:we had a hierachy originally with these terms in built e.g. normalization and this had a lot of parentage issues. 

JM:We are using the reasoner to build the hierarchy we have - we avoid multiple inheritance, also more maintainable.

JM:Input and output - dt has 'non realizable info entity' - these terms may not live in OBI for ever. We may import these in future.

RP:Ontolology is on SVN?

JM/PRS:Yes and is all DL. 

JM:The complexity of describing input/outputs allows use to futureproof things. We need to say some things about some dts. E.g. Log base 10 - we no way to represent this in OBI. Due to things being unclear with BFO. Some transformations have a feature e.g. log - allows capture difference between log base 10 and log base 2. Shouldn't be here in the long term. 

HP:Is under data transformation, not really there

MC:For convenience we could assert it under OWL thing for now

JM:Will not stay there for sure. We have not reached a satisfactory conclusion. BS thinks that numbers should be under a number ontology. Better live in the information ontology.

RP:Is OBI operational? Will show some applications where this will be implemented

MC:We have systems for maintaining stability, ids, etc, and meaning not just labels. We guarantee to you that the ids stay the same. 

RP:But position may change?

MC:If log base moves, we need to decide if changes the meaning. We then deprecate and change.

RP:What's the current percentage that is stable.

PRS:Until we have run the use cases and we are confident that we can do this, then this will be announced. 

RP:A chicken and egg problem. Our systems are experimental - this is OK for us, is  good test bed.

MC:As of today, the meaning is in the term, this is the base unit. As we have stable ids, is OK to use as a CV. As term position may change, and not all is complete you may not want to use it further. 

JM:That's fair. We need to get to input and ouput. Not there for a fully functional knowledge basis.

RP:Rupali who is in my group. She's working with ontologies, but she's yet not fully trained yet in all our processes - but she's been interacting with the OBO groups.

JM:looking at the protege file. 

PRS:Responding to RP: Variables can be role, or can be part of plan or process. Still unresolved as to their location.

HP:Are variables anywhere at present?

MC:They are not anywhere. This goes back to an issue in BFO. 

AI:Hammer BFO/IO for answers on where variables will be in the ontology. Add this to the agenda for Vancouver.

Discussion on the web version of Protege - very slow, loading protege as an applet.

RP:A group from Beijing have a web based version of Protege, will visit Beijing shortly and  - I can send an email about that.

RP: I sent a long list of stat methods. We are working on inputs for those. Rupali is the preson working on that. Is a very long list and we are slowly going through this.

AI:Follow up on input/output lists for zelig - with Rupali

JM:We have had some statisticians look at this and added some new classification hierarchy.

MC:we release a new version end of every month. We are waiting for the MSI issue. We were waiting for the feedback from the OBI coordinators.

MM:Why are center calculations separated from averaging. A center calc is an average. 'Average' means mean median mode these are synonyms. Average should be a center calculation

AI:'center calculation' and 'averaging data transformation' defined classes need attention. MM thinks that these could be conflated. Moving average needs to be under both. Data imputation possibly incorrect - could be a class in itself. Need a new defined class for that - probably objective. 

MM:A moving average is a centre calc done over time, or a series of windows - is an average calc just done in a series rather than a single dataset. Usually used with time series data for smoothing in a window based form. Is still an average. 

RP:Rather than having a single class, a moving average is not. nec a mean. So centre calc relation with time?

RB:At least moving average under both.

RP:Is moving average a different type of average?

MM:Is just over a different kind of data

PRS:Needs the window parameter

RP:Is really a different class, or is child class plus some parameter  - like time, window size

PRS:can be qualified on the input.

MM:An objective then, or a moving mean child of mean? We discuss whether moving mode has ever been used.

MM:Mode is used for categorical data.

RB:So we would have moving mean, under mean

MM:Do we have lowess localized and regressio smoother? Really a moving average is the same kind of thing as a window. In Lowess we do regression over a window. In moving average similar

JM:Suggest that we make a definition in terms of an objective with some extra input e.g. for the window size. Would then be able to add easily to some other sort of term, e.g. lowess. 

MM:Might work.

RB:Where's C means?

MM:K means?

RB:K means is there, that's why I was wondering about C means

MM/JM: what's C means

RB:K means need to chose clusters, C means not the case

MM:Fuzzy?

AI:Need to add the fuzzy clustering methods -
http://home.dei.polimi.it/matteucc/Clustering/tutorial_html/cmeans.html

MM:suggest that we change class discovery to pattern discovery. Can use class and also cluster on the basis of the samples, genes vs. class. They are not synonyms in this case.

AI:Find information for B transformation (existing term) - need an objective. - RB

AI:Background correction - changes to an objective. RB

RP:Do you cite papers?

JM:We always try to cite something, we will write it ourselves where we make a general definitions. 

MM:Here we'd need many defs for many technologies, so we wrote our own definition

MM:Loess is under curve setting and is also its own class. Is that OK? Also looking at loess scale group terms.

RP:The question for modelling this plus the moving average - somethinh similar. MA a centre measure some stratification of the data. Loess scale group scaling here transforming the data rather than fitting the data. Always the method and something else. The class is the relationship between two other classes

MC:This is what we think of as a defined class. Averaging data trans is-a data trans and some other properties

RP:The Zelig package from R - the have some structure built in. 

http://gking.harvard.edu/zelig/

PRS:We could use has_part relations to define that we do this doing some particular thing?

RP:May or may not be useful. 

JM:As a general rule, the more you can say about each class, the richer it becomes

RP:Zelig says that there is one method -'generalized linear models' and different distribution families

JM:Is this a feature of the process or the output data?

MM:Is a property of the data - the distribution. 

RP:I agree, but the method is different due to the distribution

MM:general linear model is really rich

MC:we can say something about the input.

RP:for one type of unput like count, you can mult distributions. Neg bionomial, poisson. Input being count, and method split across difft dist families as an example.

Use case: research question. Dataset trial clinical, 1300 patients, try to predict no of subjects enrolled per site. I am the PI of the trial, 150 sites worldwide, create a model to say which sites to select - each person in time for cost/time commitment. I enroll all as as site, all sites recruit. I want a model to decide which sites I retain in the site. I use a bionomial count model, how do we find a count model for a count series. Once i include your prev. patterns of enrollment my model will do better at predicting. I want to model to account for base line variables, plus previous patterns of enrollment. Time series model has cont dep variable. Looked for time series for count variable, found experimental variables. This ontology would help - Base line var, count dependent var, time series etc - I need a way to find a model.

Hypothesis - base line variable weakest predictor, but that previous patterns is likely the best thing.

MM:response variable is a count=patients enrolled. Dist of response var determine what linear model you need. 

RP:Not 1:1 can have multiple models per variable

JM:We do have some examples of hypothesis testing where we say things about what kinds of data are allowed. We have a spreadsheet of all

RP:I was trying to get at the question what determines the choice of method.

MM:All of the things mentioned come under the general linear model, type of glm is determibed by dist of response variable and not the predictors. 

RP:method varies dep. on what the predictors are.

MM:There may not be a method in this case, at least not an optimal one

HP:For OBI though you are using the ontology to say given x parameters, what are the available methods?

JM:This is a good query - I have this data, has some distributions, what dt can I run. We need the inputs on the dts to do this. We can then answer the query

RP:In my group - 'here's the question what's the best analysis method' happens all the time. There are interesting effects with 'last push effects' - get 'seasons' in the data - that relate to length and phase of recruitment.

RP:We formulate qu's based on variables and ontology can suggest and then show what results would look like. In Item response theory (IRT), if say scale to measure a condition, IRT allows to pick questions and cf have a latent construct. See a database and has a data dictionary and data that relates to it, idea of linking scales, by time a physician has a dataset and has some data, clinicians need to see a previous example.

MC:Does the input/output work

RP:The research question is the extra part

HP:So what's needed here is the switch to the knowledge base model where the application of a protocol i.e. data trans application is visible.

==Checking through the agenda==

Discussion about what to do about SW, whether this will end up in Denrie/IO. JM thinks that this will not end up in these branches based on a discussion with Alan, though what Larissa is proposing may change things.

TB:Suggests that we also talk about the manuscript. To do Friday am

PRS:Hypothesis testing. I already added terms related to this

MM:FDR is under a different heading.
